---
title: "STAT380 Final Project"
author: "Jacob Gavin, Bryson Davis, Abhilash Katigiri, Taegwon Lee"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
# Load libraries
library(readr)
library(dplyr)
library(ggplot2)
```

```{r}
# Import datasets
games_p1 <- read.csv('./data/CODGames_p1_380.csv')
games_p2 <- read.csv('./data/CODGames_p2_380.csv')
gamemodes <- read.csv('./data/CODGameModes.csv')
maps <- read.csv('./data/CODMaps.csv')

```

# Data Cleaning and Visualization (no GenAI)
Relevant Information: (Complete without using Generative AI) Prior to each online match, players in the
game lobby are presented with two options for the battlefield of the upcoming game (`Map1` and
`Map2`). The players have the option to vote and the resulting vote is recorded in the `MapVote` column.
The winning map is listed in the `Choice` column. In the event of a tie vote, the map listed in `Map1` is
chosen. (Games for which the player entered the lobby after the vote has taken place have no information
in `Map1` and `Map2` but have the winning map presented in `Choice`.)
4
Research Question: Which maps are the most likely to win the map vote when they are an option?
Notes: To answer this question, write a paragraph (or more) discussing how you plan to answer this
question. Be sure to address the data quality issues mentioned below and discuss how you will do the
calculations. Then, write code and answer the question. (If I must answer questions about your
approach/decision making process by reading your code rather than your discussion, you will lose points.)


As part of your solution, you should calculate the proportion/probability that a map wins the vote given
that it was a candidate. 
To do this, you will have to calculate the number times that each map was listed as
a candidate (Map1 or Map2) and earned more votes than the other candidate. As part of this, you should
consider whether a given map won the vote by getting more votes than the other option or if it was
selected since it was `Map1` and the vote was a tie. You should also include a visualization of the results.
There might be some data quality issues (such as misspelled map names and extra (trailing) blanks in
some entries) to solve for this problem. You can find the proper names/spellings in the CODMaps.csv
file. To full receive full credit, you must write code to solve these issues rather than editing the .csv files.

## Approach
To answer the research question, we will first need to clean the data in the `Map1`, `Map2`, and `Choice` columns of the dataset. This includes removing any trailing spaces and correcting any misspellings by cross-referencing with the `CODMaps.csv` file.

Once the data cleaning is complete, we will create a new dataframe, consisting 
of the `Map1`, `Map2`, and `Choice` columns from both datasets.
We will then calculate the number of times each map was listed as a candidate 
(either in `Map1` or `Map2`) and how many times it won the vote.


Finally, we will calculate the proportion of wins for each map and create a visualization to show the results.

```{r}
# Clean the Map1, Map2, and Choice columns
games_p1$Map1 <- trimws(games_p1$Map1)
games_p1$Map2 <- trimws(games_p1$Map2)
games_p1$Choice <- trimws(games_p1$Choice)
games_p2$Map1 <- trimws(games_p2$Map1)
games_p2$Map2 <- trimws(games_p2$Map2)
games_p2$Choice <- trimws(games_p2$Choice)

# Combine the two datasets
games_combined <- rbind(games_p1, games_p2)

# fix leading and trailing whitespaces of maps
games_combined$Map1 <- gsub("\\s+", " ", games_combined$Map1)
games_combined$Map2 <- gsub("\\s+", " ", games_combined$Map2)
games_combined$Choice <- gsub("\\s+", " ", games_combined$Choice)
# remove leading whitespace
games_combined$Map1 <- gsub("^\\s+", "", games_combined$Map1)
games_combined$Map2 <- gsub("^\\s+", "", games_combined$Map2)
games_combined$Choice <- gsub("^\\s+", "", games_combined$Choice)


# replace empty strings with NA
games_combined$Map1[games_combined$Map1 == ""] <- NA
games_combined$Map2[games_combined$Map2 == ""] <- NA
games_combined$Choice[games_combined$Choice == ""] <- NA

# remove rows where `Choice` is NA
games_combined <- games_combined[!is.na(games_combined$Choice), ]

# create a new dataframe with the correct map names
map_names <- unique(c(games_combined$Map1, games_combined$Map2, games_combined$Choice))
map_names <- map_names[map_names != ""]
map_names <- map_names[!is.na(map_names)]
map_names <- unique(map_names)


# check each map1, map2, and choice, and ensure that they exist in correct_map_names.
incorrect_map1 <- setdiff(games_combined$Map1, map_names)
incorrect_map2 <- setdiff(games_combined$Map2, map_names)
incorrect_choice <- setdiff(games_combined$Choice, map_names)

```

Now that we've completed the general data cleaning, We move on to correcting 
misspelled map names. There may be a more elegant way to do this with automatic 
spell checking, but for the purposes of this finite data set, we can brute-force 
approach the misspellings. We will use the `gsub` function to replace the incorrect
spellings with the correct ones. We will also remove any leading or trailing spaces
from the map names.

```{r}


games_combined$Map1 <- gsub("Ruah", "Rush", games_combined$Map1)
games_combined$Map1 <- gsub("Riad", "Raid", games_combined$Map1)
games_combined$Map1 <- gsub("Striek", "Strike", games_combined$Map1)
games_combined$Map1 <- gsub("Stirke", "Strike", games_combined$Map1)
games_combined$Map1 <- gsub("Collaterol Strike", "Collateral Strike", games_combined$Map1)
games_combined$Map1 <- gsub("Deprogam", "Deprogram", games_combined$Map1)
games_combined$Map1 <- gsub("^Collateral$", "Collateral Strike", games_combined$Map1)
games_combined$Map1 <- gsub("Drive-in", "Drive-In", games_combined$Map1)

games_combined$Map2 <- gsub("Miami Stirke", "Miami Strike", games_combined$Map2)
games_combined$Map2 <- gsub("^Collateral$", "Collateral Strike", games_combined$Map2)
games_combined$Map2 <- gsub("Drive-in", "Drive-In", games_combined$Map2)
games_combined$Map2 <- gsub("yamantau", "Yamantau", games_combined$Map2)
games_combined$Map2 <- gsub("Miami Sstrike", "Miami Strike", games_combined$Map2)
games_combined$Map2 <- gsub("Amrada Strike", "Armada Strike", games_combined$Map2)
games_combined$Map2 <- gsub("Nuketown '84 Halloween", "Nuketown '84 Halloween", games_combined$Map2)


games_combined$Choice <- gsub("^Collateral$", "Collateral Strike", games_combined$Choice)
games_combined$Choice <- gsub("APocalypse", "Apocalypse", games_combined$Choice)
games_combined$Choice <- gsub("Apocolypse", "Apocalypse", games_combined$Choice)
games_combined$Choice <- gsub("Drive-in", "Drive-In", games_combined$Choice)
games_combined$Choice <- gsub("Collaterel Strike", "Collateral Strike", games_combined$Choice)
games_combined$Choice <- gsub("Deisel", "Diesel", games_combined$Choice)
```

Now that we've corrected spellings, we are going to verify that the maps are correct.
Ideally, the output of this block will only be the NA values, which we will deal 
with in a later step.

```{r}
# Verify that the maps are correct
incorrect_map1 <- setdiff(games_combined$Map1, map_names)
incorrect_map2 <- setdiff(games_combined$Map2, map_names)
incorrect_choice <- setdiff(games_combined$Choice, map_names)
print(paste("Incorrect Map1 names:", paste(incorrect_map1, collapse = "|")))
print(paste("Incorrect Map2 names:", paste(incorrect_map2, collapse = "|")))
print(paste("Incorrect Choice names:", paste(incorrect_choice, collapse = "|")))
```



Through use of gsub, we corrected the spellings of maps that were recorded
incorrectly in the dataset. We also removed leading and trailing spaces from the
map names.

Becuase of the phrasing of the question, "To do this, you will have to calculate the number times that each map was listed as a candidate (Map1 or Map2) and earned more votes than the other candidate. As part of this, you should consider whether a given map won the vote by getting more votes than the other option or if it was selected since it was Map1 and the vote was a tie.",  We can assume that if the player joined the match late and Map1 and Map2 are NA, we should not use this data, as it is impossible to determine what was the 
losing map.

Next we need to convert the formatting of MapVote to be either a tie which we 
will denote as 0, or a win which we will denote as 1. because there are never 
more than 9 people voting, the votes will be single digits.
We will extract the first character of the MapVote column and the last character
If the characters are equal, we can conclude that it was a tie.
```{r}
# First, we create a new dataframe with the Map1, Map2, MapVote, and Choice columns
map_votes <- games_combined %>%
  select(Map1, Map2, MapVote, Choice)

# Next, we will remove any rows where Map1 or Map2 are NA, as mentioned previously.
map_votes <- map_votes %>%
  filter(!is.na(Map1) & !is.na(Map2))

# check first and last character, to determine if it was a tie.
map_votes <- map_votes %>%
  mutate(MapVote = ifelse(substr(MapVote, 1, 1) == substr(MapVote, nchar(MapVote), nchar(MapVote)), 0, 1))

# Now that we have identified all the ties, we can remove them from the dataset
map_votes <- map_votes %>%
  filter(MapVote == 1)

# we will use a hash map to count how many times each map was listed as a candidate,
# as well as how many times it won the vote
map_counts <- data.frame(Map = unique(c(map_votes$Map1, map_votes$Map2)), Count = 0)

# add another empty column to the map_counts dataframe to count the number of times each map wins the vote
map_counts <- map_counts %>%
  mutate(WinCount = 0)
# Now we will iterate through the map_votes data frame and count how many times each map was listed in Map1 


for (i in 1:nrow(map_votes)) {
  map1 <- map_votes$Map1[i]
  map2 <- map_votes$Map2[i]
  # increment the counts for map1 and map2
  map_counts[map_counts$Map == map1, "Count"] <- map_counts[map_counts$Map == map1, "Count"] + 1
  map_counts[map_counts$Map == map2, "Count"] <- map_counts[map_counts$Map == map2, "Count"] + 1
}

# Now, go through and update WinCount for each time a map wins the vote
for (i in 1:nrow(map_votes)) {
  map1 <- map_votes$Map1[i]
  map2 <- map_votes$Map2[i]
  choice <- map_votes$Choice[i]
  # if the choice is map1, increment the win count for map1
  if (choice == map1) {
    map_counts[map_counts$Map == map1, "WinCount"] <- map_counts[map_counts$Map == map1, "WinCount"] + 1
  } else  if (choice == map2) {
    # otherwise, increment the win count for map2
    map_counts[map_counts$Map == map2, "WinCount"] <- map_counts[map_counts$Map == map2, "WinCount"] + 1
  }
  else{
    # if the choice is neither map1 nor map2, print all 3 values for debugging
    # Ideally, this line will never execute
    print(paste("Map1:", map1, "Map2:", map2, "Choice:", choice))
  }
}

# Now that we have the counts, we can calculate the proportion of wins for each map
map_counts <- map_counts %>%
  mutate(Proportion = WinCount / Count)
# Now we can create a bar plot to visualize the results
# We will plot this data in ascending order
map_counts <- map_counts %>%
  arrange(Proportion)
# Create a bar plot of the results
ggplot(map_counts, aes(x = reorder(Map, Proportion), y = Proportion)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Proportion of Wins for Each Map", x = "Map", y = "Proportion of Wins") +
  theme_minimal()
```


With this, we have successfully cleaned the data, and calculated the proportion of wins for each map.

The only notable outlier is "Nuketown '84 Halloween". This map was only listed as 
an option once, and won the vote. This would not be considered statistically significant,
as the sample size is one. Based on the name, this was likely a limited time map,
possibly only available on halloween, which would explain both why it only appeared 
as an option once, as well as why it won the vote (not many chances to play this map.)

# Data Cleaning and Visualization (with GenAI)
Repeat Task 1 using a generative AI of your choice. To answer this question, mention the tool (including
version number if appropriate) you have selected. Then, discuss the prompt(s) you have used and provide
the solution produced by the generative AI. While it is fine to paste the question into the generative AI as
your first prompt, you should also use additional follow-up prompts if it is beneficial to do so. Be sure to
discuss all prompts used in your report.
Then, implement the generative AI solution.
Finally, and most importantly, you should compare your solution from Task 1 to the generative AI
solution. Discuss similarities/differences, strengths/weaknesses, etc., and provide an overall assessment of
which solution is better. The discussion should consider the correctness of the answers and should be
substantial. Demonstrate that you have given the comparison considerable thought by making at least 3
substantial points as part of your comparison. Each point should take the form of a well-written
paragraph.

# Inference

Relevant Information: There are a variety games types (GameType variable) within this dataset. The
difference between the game types is that players have different objectives for the game. For instance, in
the game type “Hardpoint”, teams earn points by capturing and defending a location. In “TDM” teams
earn points by eliminating enemy opponents. As these game types have different objectives and may last
for different amounts of time, the game type might affect the TotalXP earned.
Research Question: How does the game type affect TotalXP after accounting for the Score?

Notes: Score refers to the player’s score, not the “score” of the match (i.e., not the Result column). This
answer requires some data wrangling that may require knowledge that we have not covered. (Again, part
of the skillset you are working to develop is learning how to answer questions you have not seen
previously.) In particular, there is no distinction between HC – TDM and TDM, no difference between
HC – Hardpoint and Hardpoint, and so on for the other game types. Write code to clean the values in the
GameType column to reflect this information. Then, perform an exploratory data analysis by create
appropriate visualizations/summary statistics that explore the distribution of the variables and show the
relationship between TotalXP, Score, and GameType. (You decide on the type/number of visualizations,
but the analysis should be complete.) Finally, build an appropriate model for TotalXP based on Score and
GameType. You should use the model to then answer the research question.

#Approach 

First, let's join our datasets and clean the GameType column:

```{r}
# joins the datasets
games_combined <- rbind(games_p1, games_p2)

# Cleans the GameType column by removing "HC - "
games_combined$GameType <- gsub("HC - ", "", games_combined$GameType)

# Checks the unique game types
unique_game_types <- unique(games_combined$GameType)
print(unique_game_types)

# Remove rows with missing values 
inference_data <- games_combined %>%
  filter(!is.na(GameType) & !is.na(TotalXP) & !is.na(Score))

# Summary of the stats by game type
summary_stats <- inference_data %>%
  group_by(GameType) %>%
  summarize(
    Count = n(),
    Mean_Score = mean(Score),
    Mean_TotalXP = mean(TotalXP),
    Median_Score = median(Score),
    Median_TotalXP = median(TotalXP),
    SD_Score = sd(Score),
    SD_TotalXP = sd(TotalXP)
  ) %>%
  arrange(desc(Mean_TotalXP))

print(summary_stats)

# Distribution of TotalXP by game type
ggplot(inference_data, aes(x = TotalXP)) +
  geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
  facet_wrap(~ GameType, scales = "free_y") +
  labs(title = "Distribution of TotalXP by Game Type",
       x = "Total XP",
       y = "Count") +
  theme_minimal()

# Distribution of Score by game type
ggplot(inference_data, aes(x = Score)) +
  geom_histogram(bins = 30, fill = "darkgreen", alpha = 0.7) +
  facet_wrap(~ GameType, scales = "free_y") +
  labs(title = "Distribution of Score by Game Type",
       x = "Score",
       y = "Count") +
  theme_minimal()

# Boxplots of TotalXP by GameType
ggplot(inference_data, aes(x = reorder(GameType, TotalXP, FUN = median), y = TotalXP)) +
  geom_boxplot(fill = "lightblue") +
  coord_flip() +
  labs(title = "TotalXP by Game Type",
       x = "Game Type",
       y = "Total XP") +
  theme_minimal()

#  Score and TotalXP by GameType
ggplot(inference_data, aes(x = Score, y = TotalXP, color = GameType)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between Score and TotalXP by Game Type",
       x = "Score",
       y = "Total XP") +
  theme_minimal() +
  theme(legend.position = "bottom")

# For better visualization, individual plots for the top game types
top_game_types <- names(sort(table(inference_data$GameType), decreasing = TRUE)[1:4])

ggplot(inference_data %>% filter(GameType %in% top_game_types), 
       aes(x = Score, y = TotalXP)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  facet_wrap(~ GameType) +
  labs(title = "Score vs TotalXP for Most Common Game Types",
       x = "Score",
       y = "Total XP") +
  theme_minimal()
```

We can see different patterns:

Different game types show different amounts of TotalXP, some game types have higher XP than others.
There is a positive correlation between Score and TotalXP in all game types.
The slope of the relationship between Score and TotalXP is different by game type.
Some game types have a higher baseline TotalXP with no connection to Score.


Let's build and compare two models:

A model with main effects and a model with interaction effects

```{r}
# Model with main effects
main_effects_model <- lm(TotalXP ~ Score + GameType, data = inference_data)
summary_main <- summary(main_effects_model)
print(summary_main)

# Model with interaction effects
interaction_model <- lm(TotalXP ~ Score * GameType, data = inference_data)
summary_interaction <- summary(interaction_model)
print(summary_interaction)

# Comparing
anova_result <- anova(main_effects_model, interaction_model)
print(anova_result)

# see which model is better from the ANOVA test
if (anova_result$`Pr(>F)`[2] < 0.05) {
  final_model <- interaction_model
  print("The interaction model is better than the main effects model.")
} else {
  final_model <- main_effects_model
  print("There is no improvement with the interaction model over the main effects model.")
}

# Check model
par(mfrow = c(2, 2))
plot(final_model)

#prediction data
pred_data <- expand.grid(
  Score = seq(min(inference_data$Score), max(inference_data$Score), length.out = 100),
  GameType = unique(inference_data$GameType)
)

# predictions
pred_data$PredictedXP <- predict(final_model, newdata = pred_data)

# Plot the model
ggplot() +
  geom_point(data = inference_data, aes(x = Score, y = TotalXP, color = GameType), alpha = 0.3) +
  geom_line(data = pred_data, aes(x = Score, y = PredictedXP, color = GameType), size = 1) +
  labs(title = "Model Predictions of TotalXP by Score and Game Type",
       x = "Score",
       y = "Total XP") +
  theme_minimal() +
  theme(legend.position = "bottom")

#predictions for the top game types
ggplot() +
  geom_point(data = inference_data %>% filter(GameType %in% top_game_types), 
             aes(x = Score, y = TotalXP, color = GameType), alpha = 0.3) +
  geom_line(data = pred_data %>% filter(GameType %in% top_game_types), 
            aes(x = Score, y = PredictedXP, color = GameType), size = 1) +
  facet_wrap(~ GameType) +
  labs(title = "Model Predictions for Top Game Types",
       x = "Score",
       y = "Total XP") +
  theme_minimal()

#GameType effects
if (identical(final_model, main_effects_model)) {
  # For main effects model, extract GameType coefficients
  coefs <- coef(final_model)
  game_effects <- data.frame(
    GameType = names(coefs)[-c(1:2)],
    Effect = as.numeric(coefs[-c(1:2)])
  )
  game_effects$GameType <- gsub("GameType", "", game_effects$GameType)
  
  # reference level with effect = 0
  ref_level <- setdiff(unique(inference_data$GameType), game_effects$GameType)
  game_effects <- rbind(game_effects, data.frame(GameType = ref_level, Effect = 0))
  
  #GameType effects
  ggplot(game_effects, aes(x = reorder(GameType, Effect), y = Effect)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    coord_flip() +
    labs(title = "Effect of Game Type on TotalXP (After Controlling for Score)",
         x = "Game Type",
         y = "Effect on TotalXP") +
    theme_minimal()
} else {

  #effects at specific Score values
  score_levels <- c(
    min(inference_data$Score),
    median(inference_data$Score),
    max(inference_data$Score)
  )
  
  for (score_val in score_levels) {
    pred_at_score <- predict(final_model, 
                             newdata = data.frame(Score = score_val, 
                                                 GameType = unique(inference_data$GameType)))
    score_effects <- data.frame(
      GameType = unique(inference_data$GameType),
      Effect = pred_at_score - pred_at_score[1]  # Reference to first game type
    )
    
    print(paste("Game Type Effects at Score =", score_val))
    print(score_effects)
    
    # Plot
    ggplot(score_effects, aes(x = reorder(GameType, Effect), y = Effect)) +
      geom_bar(stat = "identity", fill = "steelblue") +
      coord_flip() +
      labs(title = paste("Effect of Game Type on TotalXP at Score =", score_val),
           x = "Game Type",
           y = "Effect on TotalXP (relative to reference)") +
      theme_minimal()
  }
}
```



The type of game you play changes how much TotalXP you earn. Each game mode has a different XP rate, and some give you more XP per Score point than others. According to the data, Domination gives the highest XP per point, next is Hardpoint, Kill Confirmed, and Team Deathmatch gives the lowest.


The statistical model (TotalXP ~ Score * GameType) showed that game types change how Score turns into XP. This model beat a simpler one (TotalXP ~ Score + GameType) with a p-value of 0.0000329, showing it’s reliable. It also explained 35.7% of TotalXP differences (R² = 0.3568).

XP Rates by Game Type, Domination gives the Highest XP per Score point (steepest slope). Hardpoint has the Second-highest XP rate. Kill Confirmed is Middle of the pack. TDM is the Lowest XP per point (flattest slope).


Compared to Domination, TDM: -3.182 (p = 0.07961, almost significant). Kill Confirmed: -2.412 (p = 0.26344). 
Hardpoint: -1.752 (p = 0.33680).


# Prediction

Relevant Information: In this task, your goal is to compare a variety of classification methods. In
particular, you should write your own research question that can be answered by comparing the
effectiveness of various classification methodologies. To demonstrate your understanding of these
methods, you should implement two classification methods from class, one of which must be random
forest, and a third method that we will not cover in class. (The purpose of the using a method we did not
cover is I want you to practice learning about a method and its implementation on your own. Basically,
find a tutorial that explains the method and how to implement it.) You will then have to compare the
results and decide which method was the most effective.
Research Question: Write your own question and be sure that the question and answer are clearly written
in your report.
Notes: Since you will be using random forest, do not use a decision/classification tree as one of your other
methods. For this problem, you should provide a brief description of the methods that you will use. (A
description is more than listing the name of the procedure. You should describe how the procedure
works.) You will implement and compare the effectiveness of these methods. As part of this process, you
will have to make a number of decisions such as whether you will do any data wrangling (maybe you
remove partial matches, maybe you create new variables, etc.), which methods will you use, how will you
fairly compare the results between methods, which method is best etc. All of these decisions should be
included in your report. If I have to learn about your decisions/analysis by reading your code, you will
lose points.

#### Study goal
The objective is to predict whether a match is played in **Hardcore (HC)** or **Core** mode using only in‑match performance statistics. We compare three classifiers:
1. **Logistic Regression** – linear, fully interpretable baseline
2. **Random Forest** – non‑linear ensemble (required by the assignment)
3. **Support Vector Machine with RBF kernel** – a method not covered in class
Models are tuned with 5 × repeated 5‑fold cross‑validation optimising ROC‑AUC, and final performance is assessed on a stratified 30 % hold‑out set using ROC‑AUC and Accuracy.

#### Data loading and merge
The two match logs (`CODGames_p1_380.csv`, `CODGames_p2_380.csv`) are merged into a single data frame called `games`. No cleaning is performed at this point; the aim is simply to consolidate all observations.

```{r}
library(dplyr); library(caret); library(randomForest); library(e1071); library(pROC); library(ggplot2)

p1 <- read.csv("./data/CODGames_p1_380.csv")
p2 <- read.csv("./data/CODGames_p2_380.csv")
games <- bind_rows(p1, p2)
```

#### Target variable
Rows whose `GameType` string starts with “HC – ” are labelled Hardcore, otherwise Core. The resulting factor `IsHC` is stored with the level order Core < HC to keep all downstream interpretations consistent.

```{r}
games <- games %>%
mutate(IsHC = factor(ifelse(grepl("^HC", GameType), "HC", "Core"),
levels = c("Core", "HC")))
```

#### Feature engineering
If a match‑length column is present (`Time`, `MatchTime`, or `TimeSeconds`), it is converted to minutes (`TimeMinutes`) for scale uniformity. The candidate predictor pool comprises `Score`, `Eliminations`, `Deaths`, `Damage`, `Objectives`, and the optional `TimeMinutes`. Only columns that actually exist in the dataset are retained, and rows containing missing values are dropped.

```{r}
if ("Time" %in% names(games)) games$TimeMinutes <- games$Time / 60
if ("MatchTime" %in% names(games)) games$TimeMinutes <- games$MatchTime / 60
if ("TimeSeconds"%in% names(games)) games$TimeMinutes <- games$TimeSeconds/ 60

feature_pool <- c("Score", "Eliminations", "Deaths", "Damage",
"Objectives", "TimeMinutes")
use_vars <- intersect(feature_pool, names(games))

model_df <- games %>% select(IsHC, all_of(use_vars)) %>% na.omit()
```

#### Train‑test split
A stratified split (70 % train / 30 % test) preserves the Core/HC class ratio. A fixed seed (42) ensures that results are reproducible.

```{r}
set.seed(42)
idx <- createDataPartition(model_df$IsHC, p = 0.7, list = FALSE)
train <- model_df[idx, ]
test <- model_df[-idx, ]
```

#### Cross‑validation settings
A common `trainControl` object specifies 5‑fold cross‑validation repeated three times, optimisation on ROC‑AUC, and storage of class probabilities. Using the same control parameters guarantees a fair comparison across models.

```{r}
ctrl <- trainControl(method = "repeatedcv",
number = 5, repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final")
```

#### Model training and tuning
* Logistic Regression – converts a linear combination of features into a probability via the logistic (sigmoid) function; coefficients can be interpreted as log‑odds, e.g. “one additional Score point multiplies the odds of HC mode by exp(β)”.
* Random Forest – builds 500 bootstrap decision trees; at each split a random subset of predictors is considered, reducing correlation among trees. Majority voting over many low‑bias, high‑variance trees lowers overall variance and guards against over‑fitting.
* SVM with RBF kernel – uses the kernel trick to map observations into an infinite‑dimensional space where a maximal‑margin hyper‑plane separates the classes. The regularisation parameter **C** controls mis‑classification tolerance, while kernel width **σ** adjusts decision‑boundary smoothness..

```{r}

log_fit <- train(IsHC ~ ., data = train,
method = "glm", family = "binomial",
metric = "ROC", trControl = ctrl)

rf_fit <- train(IsHC ~ ., data = train,
method = "rf", ntree = 500,
tuneGrid = expand.grid(mtry = c(2, 3, 4)),
metric = "ROC", trControl = ctrl,
importance = TRUE)

svm_fit <- train(IsHC ~ ., data = train,
method = "svmRadial",
preProcess = c("center", "scale"),
tuneGrid = expand.grid(sigma = 2^(-8:-6), C = 2^(0:4)),
metric = "ROC", trControl = ctrl)
```

#### Cross‑validation results
`resamples` reports each model’s mean ROC‑AUC and Accuracy with standard deviations. The accompanying dot‑plot visualises the ROC‑AUC distribution and already indicates that Random Forest is the top performer on average.

```{r}
res <- resamples(list(Logistic = log_fit,
RandomForest = rf_fit,
SVM = svm_fit))
print(summary(res))
dotplot(res, metric = "ROC")
```

#### Hold‑out performance
Applying the trained models to the 30 % test set confirms the cross‑validation findings: Random Forest achieves the highest ROC‑AUC and Accuracy, demonstrating strong generalisation beyond the training folds.

```{r}
library(pROC); library(knitr)

metric <- function(m, new) {
p <- predict(m, new, type = "prob")[,"HC"]
auc <- roc(new$IsHC, p)$auc
acc <- mean(ifelse(p > 0.5, "HC", "Core") == new$IsHC)
c(AUC = auc, Accuracy = acc)
}
holdout <- rbind(
Logistic = metric(log_fit, test),
RandomForest = metric(rf_fit, test),
SVM = metric(svm_fit, test)
)
knitr::kable(round(holdout, 3), caption = "30 % hold‑out performance")
```

#### Variable importance (Random Forest)
The Gini‑based importance plot shows that Score and Eliminations contribute most to distinguishing Hardcore matches, whereas `Objectives` and `TimeMinutes` exhibit relatively minor influence.

```{r}
# variable importance (Random Forest)
imp <- varImp(rf_fit)$importance
imp$Variable <- rownames(imp)
val_col <- if ("Overall" %in% names(imp)) "Overall" else names(imp)[1]

ggplot(imp, aes(reorder(Variable, .data[[val_col]]), .data[[val_col]])) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Random‑Forest variable importance",
x = NULL, y = "Importance") +
theme_minimal()
```

#### Overall interpretation
Random Forest delivers the best predictive power by automatically capturing non‑linear relationships and feature interactions. Logistic Regression is easy to interpret but constrained by its linear form, while SVM is competitive yet sensitive to hyper‑parameter choices and computationally heavier on larger data sets.
Future work could address potential class imbalance with resampling techniques (e.g., SMOTE) and explore additional features such as map type, game mode, or time‑of‑day to further boost model performance.



